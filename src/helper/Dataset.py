from helper.Distribution import Uniform
from helper.Datapoint import Datapoint
import numpy as np
from math import sqrt
import json


class Dataset:
    def __init__(
        self, rng, bounds, size, children, assumptions, datapoints=[], name=None
    ):
        self.meta = {
            "rng": rng,
            "domain_bounds": bounds,
            "size": size,
            "children": children,
            "experiment_assumptions": assumptions,
        }
        self.datapoints = datapoints
        if children is not None:
            self.import_datasets(children)
        if len(datapoints) == 0:
            self.generate_input()
        assert len(self.datapoints) == self.meta["size"]
        if name is None:
            self.name = hash(tuple(str(sorted(self.meta.items()))))
        else:
            self.name = name
        self.save()

    def get_size(self):
        return len(self.datapoints)

    def generate_input(self):
        inp = np.array(
            [
                Uniform(
                    self.meta["domain_bounds"][i][0], self.meta["domain_bounds"][i][1]
                ).sample(self.meta["size"])
                for i in self.meta["domain_bounds"].keys()
            ]
        )
        for n in range(self.meta["size"]):
            lmb = float(inp[0, n])
            m = float(inp[1, n])
            theta_std = sqrt(self.meta["experiment_assumptions"]["gamma"] * lmb)
            ass = {
                **self.meta["experiment_assumptions"],
                **{"lmb": lmb, "mean_opinion": m, "theta_std": theta_std},
            }
            dp = Datapoint(
                dict(zip(self.meta["domain_bounds"].keys(), inp[:, n].tolist())), ass
            )
            self.datapoints.append(f"""{dp.name}.json""")
        self.meta["size"] = self.get_size()

    def import_datasets(self, children):
        pass
        # check if datasets where generated by same rng
        # check if datasets have same bounds to conserve discrepancy
        # add members of datasets to members
        # add dataset names to children
        # update size

    def compute_output(self):
        for dp_name in self.datapoints:
            dp = Datapoint.from_json(f"""src\\datapoints\\{dp_name}""")
            if (dp.output is None) or (dp.output["raw"] is None):
                dp.compute_output()
        pass

    # for each Datapoint in self.members which has no output
    # Datapoint.compute_output()

    def save(self):
        file = open(f"""src\\datasets\\{self.name}.json""", mode="w")
        json.dump(self.to_json(), file, indent=1)
        pass

    def compute_aggregated_output(self, n):
        # Compute the effective 'histogram' of the solution over n equispaced intervals.
        for dp_name in self.datapoints:
            dp = Datapoint.from_json(f"""src\\datapoints\\{dp_name}""")
            if dp.output is None:
                dp.compute_output()
            if "aggregated" not in dp.output:
                dp.compute_aggregated_output(n)
        pass

    def to_json(self):
        return self.__dict__

    @staticmethod
    def from_json(filename):
        f = open(filename)
        set = json.load(f)
        return Dataset(
            set["meta"]["rng"],
            set["meta"]["domain_bounds"],
            set["meta"]["size"],
            set["meta"]["children"],
            set["meta"]["experiment_assumptions"],
            set["datapoints"],
            set["name"],
        )
